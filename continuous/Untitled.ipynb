{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67676f55-3995-4565-a08e-83bbbf9f7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qpsolvers import solve_qp\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff3af22-d24f-461d-b1eb-a2b56be7c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting daqp\n",
      "  Using cached daqp-0.5.1.tar.gz (132 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: daqp\n",
      "  Building wheel for daqp (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for daqp \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Could not find daqp directory\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'daqp' extension\n",
      "  \u001b[31m   \u001b[0m error: unknown file type '.pxd' (from 'daqp.pxd')\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for daqp\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build daqp\n",
      "\u001b[31mERROR: Could not build wheels for daqp, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install daqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fa4bb-e75c-497c-9b69-8799ab718aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install qpsolvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7891de-f22e-4caa-822b-fecb9501ee59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "/ \n",
      "  - conda-forge/linux-ppc64le::gcc_impl_linux-ppc64le==12.2.0=h3a350b8_18\n",
      "  - conda-forge/noarch::sysroot_linux-ppc64le==2.17=h395ec9b_13\n",
      "  - conda-forge/linux-ppc64le::clang==15.0.2=ha3edaa6_0\n",
      "  - conda-forge/linux-ppc64le::binutils_impl_linux-ppc64le==2.39=h6c0ba3f_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/linux-ppc64le::shap==0.40.0=py39h92fcf75_0\n",
      "  - conda-forge/linux-ppc64le::gcc_impl_linux-ppc64le==12.2.0=h3a350b8_18\n",
      "  - conda-forge/noarch::sysroot_linux-ppc64le==2.17=h395ec9b_13\n",
      "  - conda-forge/linux-ppc64le::clang==15.0.2=ha3edaa6_0\n",
      "  - conda-forge/linux-ppc64le::binutils_impl_linux-ppc64le==2.39=h6c0ba3f_0\n",
      "  - conda-forge/linux-ppc64le::numba==0.53.1=py39hd44d982_1\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/miniconda3/envs/opence-v1.7.2\n",
      "\n",
      "  added / updated specs:\n",
      "    - qpsolvers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _sysroot_linux-ppc64le_curr_repodata_hack-4|      h43410cf_13          20 KB  conda-forge\n",
      "    ca-certificates-2023.7.22  |       h0f6029e_0         146 KB  conda-forge\n",
      "    certifi-2023.7.22          |     pyhd8ed1ab_0         150 KB  conda-forge\n",
      "    cvxopt-1.2.7               |   py39ha245f30_0         533 KB  conda-forge\n",
      "    cython-0.29.28             |   py39h7781188_1         2.1 MB  conda-forge\n",
      "    dsdp-5.8                   |    hb6c3b0e_1203         268 KB  conda-forge\n",
      "    ecos-2.0.8                 |   py39h50b74dd_1          89 KB  conda-forge\n",
      "    fftw-3.3.10                |nompi_h11bfeb0_108         1.6 MB  conda-forge\n",
      "    glpk-4.65                  |    h7bbf4ef_1004         1.2 MB  conda-forge\n",
      "    gsl-2.7                    |       h68b80c3_0         4.3 MB  conda-forge\n",
      "    libblas-3.9.0              |15_linuxppc64le_openblas          13 KB  conda-forge\n",
      "    libcblas-3.9.0             |15_linuxppc64le_openblas          12 KB  conda-forge\n",
      "    liblapack-3.9.0            |15_linuxppc64le_openblas          12 KB  conda-forge\n",
      "    libosqp-0.6.3              |       h46f38da_0          76 KB  conda-forge\n",
      "    libqdldl-0.1.5             |       hbbae597_1          17 KB  conda-forge\n",
      "    metis-5.1.0                |    h46f38da_1007         3.7 MB  conda-forge\n",
      "    mpfr-4.2.1                 |       haad2271_0         536 KB  conda-forge\n",
      "    numba-0.53.1               |   py39haab0e66_0         3.4 MB\n",
      "    openssl-1.1.1w             |       ha17a0cc_0         1.9 MB  conda-forge\n",
      "    osqp-0.6.3                 |   py39h83ae58a_0         207 KB\n",
      "    qdldl-python-0.1.5         |   py39h6474468_1          96 KB  conda-forge\n",
      "    qpsolvers-2.6.0            |     pyhd8ed1ab_0          31 KB  conda-forge\n",
      "    quadprog-0.1.10            |   py39h4d17caa_0         105 KB  conda-forge\n",
      "    suitesparse-5.10.1         |       h7156e76_0         2.7 MB  conda-forge\n",
      "    tbb-2020.2                 |       h2acdbc0_4         1.5 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        24.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _sysroot_linux-pp~ conda-forge/noarch::_sysroot_linux-ppc64le_curr_repodata_hack-4-h43410cf_13 None\n",
      "  cvxopt             conda-forge/linux-ppc64le::cvxopt-1.2.7-py39ha245f30_0 None\n",
      "  cython             conda-forge/linux-ppc64le::cython-0.29.28-py39h7781188_1 None\n",
      "  dsdp               conda-forge/linux-ppc64le::dsdp-5.8-hb6c3b0e_1203 None\n",
      "  ecos               conda-forge/linux-ppc64le::ecos-2.0.8-py39h50b74dd_1 None\n",
      "  fftw               conda-forge/linux-ppc64le::fftw-3.3.10-nompi_h11bfeb0_108 None\n",
      "  glpk               conda-forge/linux-ppc64le::glpk-4.65-h7bbf4ef_1004 None\n",
      "  gsl                conda-forge/linux-ppc64le::gsl-2.7-h68b80c3_0 None\n",
      "  libblas            conda-forge/linux-ppc64le::libblas-3.9.0-15_linuxppc64le_openblas None\n",
      "  libcblas           conda-forge/linux-ppc64le::libcblas-3.9.0-15_linuxppc64le_openblas None\n",
      "  liblapack          conda-forge/linux-ppc64le::liblapack-3.9.0-15_linuxppc64le_openblas None\n",
      "  libosqp            conda-forge/linux-ppc64le::libosqp-0.6.3-h46f38da_0 None\n",
      "  libqdldl           conda-forge/linux-ppc64le::libqdldl-0.1.5-hbbae597_1 None\n",
      "  metis              conda-forge/linux-ppc64le::metis-5.1.0-h46f38da_1007 None\n",
      "  mpfr               conda-forge/linux-ppc64le::mpfr-4.2.1-haad2271_0 None\n",
      "  osqp               pkgs/main/linux-ppc64le::osqp-0.6.3-py39h83ae58a_0 None\n",
      "  qdldl-python       conda-forge/linux-ppc64le::qdldl-python-0.1.5-py39h6474468_1 None\n",
      "  qpsolvers          conda-forge/noarch::qpsolvers-2.6.0-pyhd8ed1ab_0 None\n",
      "  quadprog           conda-forge/linux-ppc64le::quadprog-0.1.10-py39h4d17caa_0 None\n",
      "  suitesparse        conda-forge/linux-ppc64le::suitesparse-5.10.1-h7156e76_0 None\n",
      "  tbb                conda-forge/linux-ppc64le::tbb-2020.2-h2acdbc0_4 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.9.24-h1084571_0 --> 2023.7.22-h0f6029e_0 None\n",
      "  certifi                            2022.9.24-pyhd8ed1ab_0 --> 2023.7.22-pyhd8ed1ab_0 None\n",
      "  openssl                                 1.1.1q-hb283c62_1 --> 1.1.1w-ha17a0cc_0 None\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  numba              conda-forge::numba-0.53.1-py39hd44d98~ --> pkgs/main::numba-0.53.1-py39haab0e66_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "liblapack-3.9.0      | 12 KB     | ##################################### | 100% \n",
      "cvxopt-1.2.7         | 533 KB    | ##################################### | 100% \n",
      "suitesparse-5.10.1   | 2.7 MB    | ##################################### | 100% \n",
      "dsdp-5.8             | 268 KB    | ##################################### | 100% \n",
      "mpfr-4.2.1           | 536 KB    | ##################################### | 100% \n",
      "openssl-1.1.1w       | 1.9 MB    | ##################################### | 100% \n",
      "qdldl-python-0.1.5   | 96 KB     | ##################################### | 100% \n",
      "_sysroot_linux-ppc64 | 20 KB     | ##################################### | 100% \n",
      "ca-certificates-2023 | 146 KB    | ##################################### | 100% \n",
      "numba-0.53.1         | 3.4 MB    | ##################################### | 100% \n",
      "libqdldl-0.1.5       | 17 KB     | ##################################### | 100% \n",
      "cython-0.29.28       | 2.1 MB    | ##################################### | 100% \n",
      "tbb-2020.2           | 1.5 MB    | ##################################### | 100% \n",
      "glpk-4.65            | 1.2 MB    | ##################################### | 100% \n",
      "quadprog-0.1.10      | 105 KB    | ##################################### | 100% \n",
      "libosqp-0.6.3        | 76 KB     | ##################################### | 100% \n",
      "certifi-2023.7.22    | 150 KB    | ##################################### | 100% \n",
      "libcblas-3.9.0       | 12 KB     | ##################################### | 100% \n",
      "ecos-2.0.8           | 89 KB     | ##################################### | 100% \n",
      "fftw-3.3.10          | 1.6 MB    | ##################################### | 100% \n",
      "qpsolvers-2.6.0      | 31 KB     | ##################################### | 100% \n",
      "gsl-2.7              | 4.3 MB    | ##################################### | 100% \n",
      "osqp-0.6.3           | 207 KB    | ##################################### | 100% \n",
      "libblas-3.9.0        | 13 KB     | ##################################### | 100% \n",
      "metis-5.1.0          | 3.7 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /opt/miniconda3/envs/opence-v1.7.2\n",
      "  uid: 69277\n",
      "  gid: 202\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge qpsolvers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef35696-a7a6-4947-9931-8414df64ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/student/student-mat.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaddde2-8f82-49ac-9955-0bdd70d36f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=[\"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\", \"reason\", \"guardian\", \n",
    "                                         \"schoolsup\", \"famsup\", \"paid\", \"activities\", \"nursery\", \"higher\", \"internet\", \"romantic\"], drop_first=True)\n",
    "df_encoded.drop([\"G1\", \"G2\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec51b8-2e39-4c24-9864-22a9c349d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_encoded.drop([\"G3\"], axis=1)\n",
    "target = df_encoded[\"G3\"]\n",
    "X = torch.tensor(features.values, dtype=torch.float)\n",
    "X = X - X.mean(dim=0)\n",
    "X = X/X.std(dim=0)\n",
    "Y = torch.tensor(target.values, dtype=torch.float)\n",
    "Y = Y - Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b04e53c-6a41-45a0-b85f-0c2bc57dca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContSolve(torch.nn.Module):\n",
    "    def __init__(self, X, Y, k, l, device):\n",
    "        super(ContSolve, self).__init__()\n",
    "        self.X = X.to(torch.device(device))\n",
    "        self.Y = Y.to(torch.device(device))\n",
    "        for tensor in [self.X, self.Y]:\n",
    "            tensor.requires_grad = False\n",
    "        self.m = self.X.shape[1]\n",
    "        self.n = self.X.shape[0]\n",
    "        self.k = k\n",
    "        self.l = l\n",
    "        self.device = torch.device(device)\n",
    "        self.ps = torch.nn.Parameter(torch.full((self.m,), self.k/self.m).to(self.device), requires_grad=True)\n",
    "        self.qs = torch.nn.Parameter(torch.full((self.n,), self.l/self.n).to(self.device), requires_grad=True)\n",
    "        \n",
    "#     def forward2(self):\n",
    "#         tilde_M = torch.einsum('m,mn,n->mn',self.ps,self.M,self.ps)\n",
    "#         init_power = torch.eye(self.m).to(self.device)-tilde_M\n",
    "#         weight_X = torch.einsum('m,mn->mn',self.ps,self.X.T)\n",
    "#         with torch.no_grad():\n",
    "#             eps_0 = torch.norm(weight_X)\n",
    "#             alpha = torch.norm(init_power)\n",
    "#             print((eps_0, alpha))\n",
    "#             print(torch.round(torch.log(self.eps*(1-alpha)/eps_0)/torch.log(alpha)+0.5))\n",
    "#             k = torch.max(1, torch.round(torch.log(self.eps*(1-alpha)/eps_0)/torch.log(alpha)+0.5))\n",
    "#         total = torch.eye(self.m).to(self.device)\n",
    "#         curr_power = torch.eye(self.m).to(self.device)\n",
    "#         for i in range(1, k+1):\n",
    "#             curr_power = torch.einsum('mn,np->mp',curr_power,init_power)\n",
    "#             total += curr_power\n",
    "#         tilde_X_terms = torch.einsum('mp,pn->mn',total,weight_X)\n",
    "#         beta = torch.einsum('mn,n->m',tilde_X_terms,self.Y) \n",
    "#         resid = self.Y - torch.einsum('nm,m->n',weight_X,beta)\n",
    "#         r2 = 1 - torch.einsum('n,n->1',resid,resid)/torch.einsum('n,n->1',self.Y,self.Y)\n",
    "#         return r2\n",
    "    \n",
    "    def forward(self):\n",
    "        scaled_X = torch.einsum('n,nm,m->nm',self.qs,self.X,self.ps)\n",
    "        scaled_Y = torch.einsum('n,n->n',self.Y,self.qs)\n",
    "        tilde_M = torch.einsum('mn,np->mp',scaled_X.T,scaled_X)\n",
    "        tilde_M_inv = torch.linalg.inv(tilde_M)\n",
    "        tilde_M_inv_Xt = torch.einsum('mn,np->mp',tilde_M_inv,scaled_X.T)\n",
    "        beta = torch.einsum('mn,n->m',tilde_M_inv_Xt,scaled_Y) \n",
    "        resid = scaled_Y - torch.einsum('nm,m->n',scaled_X,beta)\n",
    "        r2 = 1 - torch.einsum('n,n->',resid,resid)/torch.einsum('n,n->',scaled_Y,scaled_Y)\n",
    "        return r2\n",
    "    \n",
    "def project_onto_simplex(v, select, total):\n",
    "    P = 2*np.eye(total)\n",
    "    q = 2*v\n",
    "    A = np.ones((1, total))\n",
    "    b = np.array([select])\n",
    "    lb = np.zeros(total)\n",
    "    ub = np.ones(total)\n",
    "    proj = solve_qp(P, q, A=A, b=b, lb=lb, ub=ub)\n",
    "    return proj\n",
    "    \n",
    "def frank_wolfe(gradV, select, total):\n",
    "    c = -gradV\n",
    "    A_eq = np.ones((1, total))\n",
    "    b_eq = np.array([select])\n",
    "    bounds = (0, 1)\n",
    "    res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f3da54c8-a5c2-44bc-b704-798c785ee3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[1]\n",
    "n = X.shape[0]\n",
    "k = 10\n",
    "l = 40\n",
    "cs = ContSolve(X, Y, k, l, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9118d687-47d5-4db7-b1ee-2f0a86f190b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9926, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Parameter containing:\n",
      "tensor([0.1060, 0.1043, 0.1031, 0.1043, 0.1013, 0.1013, 0.1015, 0.1041, 0.1062,\n",
      "        0.1023, 0.1030, 0.1013, 0.1013, 0.1015, 0.1040, 0.1031, 0.1017, 0.1018,\n",
      "        0.1018, 0.1040, 0.1014, 0.1013, 0.1023, 0.1013, 0.1028, 0.1013, 0.1013,\n",
      "        0.1013, 0.1013, 0.1013, 0.1031, 0.1039, 0.1091, 0.1020, 0.1047, 0.1049,\n",
      "        0.1087, 0.1030, 0.1013, 0.1042, 0.1030, 0.1013, 0.1052, 0.1016, 0.1014,\n",
      "        0.1046, 0.1013, 0.1055, 0.1040, 0.1045, 0.1020, 0.1013, 0.1045, 0.1022,\n",
      "        0.1013, 0.1013, 0.1018, 0.1044, 0.1018, 0.1082, 0.1017, 0.1079, 0.1017,\n",
      "        0.1013, 0.1017, 0.1061, 0.1013, 0.1076, 0.1029, 0.1025, 0.1021, 0.1044,\n",
      "        0.1021, 0.1025, 0.1014, 0.1016, 0.1042, 0.1013, 0.1124, 0.1092, 0.1038,\n",
      "        0.1018, 0.1123, 0.1014, 0.1013, 0.1013, 0.1051, 0.1016, 0.1032, 0.1103,\n",
      "        0.1021, 0.1075, 0.1037, 0.1013, 0.1013, 0.1031, 0.1077, 0.1039, 0.1030,\n",
      "        0.1017, 0.1111, 0.1032, 0.1022, 0.1061, 0.1078, 0.1017, 0.1027, 0.1096,\n",
      "        0.1039, 0.1040, 0.1058, 0.1023, 0.1103, 0.1086, 0.1058, 0.1054, 0.1013,\n",
      "        0.1017, 0.1014, 0.1013, 0.1052, 0.1017, 0.1040, 0.1013, 0.1015, 0.1019,\n",
      "        0.1014, 0.1134, 0.1114, 0.1091, 0.1168, 0.1150, 0.1047, 0.1024, 0.1283,\n",
      "        0.1298, 0.1240, 0.1084, 0.1030, 0.1044, 0.1272, 0.1013, 0.1014, 0.1024,\n",
      "        0.1050, 0.1013, 0.1127, 0.1013, 0.1213, 0.1030, 0.1021, 0.1084, 0.1014,\n",
      "        0.1039, 0.1038, 0.1022, 0.1032, 0.1206, 0.1061, 0.1056, 0.1065, 0.1018,\n",
      "        0.1178, 0.1013, 0.1085, 0.1023, 0.1014, 0.1061, 0.1176, 0.1015, 0.1092,\n",
      "        0.1092, 0.1016, 0.1029, 0.1015, 0.1024, 0.1014, 0.1102, 0.1014, 0.1016,\n",
      "        0.1042, 0.1013, 0.1112, 0.1078, 0.1013, 0.1013, 0.1013, 0.1057, 0.1025,\n",
      "        0.1013, 0.1015, 0.1014, 0.1069, 0.1025, 0.1038, 0.1069, 0.1020, 0.1014,\n",
      "        0.1131, 0.1056, 0.1065, 0.1015, 0.1014, 0.1063, 0.1013, 0.1014, 0.1015,\n",
      "        0.1027, 0.1013, 0.1024, 0.1047, 0.1015, 0.1094, 0.1022, 0.1034, 0.1030,\n",
      "        0.1052, 0.1041, 0.1015, 0.1013, 0.1019, 0.1087, 0.1046, 0.1042, 0.1048,\n",
      "        0.1014, 0.1055, 0.1021, 0.1013, 0.1029, 0.1020, 0.1013, 0.1020, 0.1013,\n",
      "        0.1114, 0.1038, 0.1016, 0.1017, 0.1025, 0.1220, 0.1013, 0.1018, 0.1293,\n",
      "        0.1016, 0.1201, 0.1144, 0.1022, 0.1047, 0.1039, 0.1034, 0.1013, 0.1024,\n",
      "        0.1013, 0.1027, 0.1014, 0.1014, 0.1019, 0.1068, 0.1044, 0.1429, 0.1123,\n",
      "        0.1034, 0.1014, 0.1014, 0.1194, 0.1108, 0.1025, 0.1025, 0.1019, 0.1076,\n",
      "        0.1046, 0.1062, 0.1021, 0.1047, 0.1013, 0.1047, 0.1032, 0.1021, 0.1013,\n",
      "        0.1018, 0.1106, 0.1014, 0.1020, 0.1032, 0.1027, 0.1015, 0.1135, 0.1017,\n",
      "        0.1014, 0.1013, 0.1013, 0.1020, 0.1028, 0.1099, 0.1013, 0.1018, 0.1292,\n",
      "        0.1022, 0.1030, 0.1054, 0.1014, 0.1056, 0.1033, 0.1052, 0.1068, 0.1020,\n",
      "        0.1116, 0.1014, 0.1059, 0.1016, 0.1127, 0.1039, 0.1014, 0.1013, 0.1081,\n",
      "        0.1017, 0.1272, 0.1014, 0.1013, 0.1032, 0.1014, 0.1014, 0.1013, 0.1045,\n",
      "        0.1050, 0.1014, 0.1084, 0.1017, 0.1016, 0.1039, 0.1034, 0.1093, 0.1265,\n",
      "        0.1248, 0.1202, 0.1038, 0.1018, 0.1245, 0.1053, 0.1013, 0.1023, 0.1166,\n",
      "        0.1033, 0.1188, 0.1013, 0.1025, 0.1072, 0.1013, 0.1037, 0.1094, 0.1023,\n",
      "        0.1013, 0.1013, 0.1016, 0.1013, 0.1013, 0.1039, 0.1013, 0.1015, 0.1054,\n",
      "        0.1072, 0.1040, 0.1017, 0.1068, 0.1030, 0.1014, 0.1014, 0.1159, 0.1022,\n",
      "        0.1013, 0.1018, 0.1044, 0.1014, 0.1062, 0.1125, 0.1013, 0.1115, 0.1018,\n",
      "        0.1078, 0.1027, 0.1013, 0.1042, 0.1020, 0.1203, 0.1077, 0.1019, 0.1022,\n",
      "        0.1250, 0.1022, 0.1117, 0.1015, 0.1037, 0.1022, 0.1044, 0.1020],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([-3.9857e+01, -1.9864e+01, -1.3199e+01, -9.8672e+00, -7.8681e+00,\n",
      "        -6.5355e+00, -5.5837e+00, -4.8699e+00, -4.3150e+00, -3.8710e+00,\n",
      "        -3.5078e+00, -3.2051e+00, -2.9492e+00, -2.7299e+00, -2.5398e+00,\n",
      "        -2.3736e+00, -2.2269e+00, -2.0965e+00, -1.9799e+00, -1.8749e+00,\n",
      "        -1.7800e+00, -1.6938e+00, -1.6151e+00, -1.5429e+00, -1.4766e+00,\n",
      "        -1.4153e+00, -1.3587e+00, -1.3061e+00, -1.2572e+00, -1.2115e+00,\n",
      "        -1.1688e+00, -1.1287e+00, -1.0911e+00, -1.0557e+00, -1.0223e+00,\n",
      "        -9.9081e-01, -9.6101e-01, -9.3279e-01, -9.0601e-01, -8.8058e-01,\n",
      "        -8.5638e-01, -8.3335e-01, -8.1138e-01, -7.9042e-01, -7.7040e-01,\n",
      "        -7.5126e-01, -7.3293e-01, -7.1536e-01, -6.9852e-01, -6.8236e-01,\n",
      "        -6.6683e-01, -6.5190e-01, -6.3754e-01, -6.2371e-01, -6.1039e-01,\n",
      "        -5.9754e-01, -5.8514e-01, -5.7317e-01, -5.6161e-01, -5.5044e-01,\n",
      "        -5.3964e-01, -5.2918e-01, -5.1906e-01, -5.0926e-01, -4.9976e-01,\n",
      "        -4.9054e-01, -4.8161e-01, -4.7294e-01, -4.6452e-01, -4.5635e-01,\n",
      "        -4.4840e-01, -4.4068e-01, -4.3317e-01, -4.2586e-01, -4.1874e-01,\n",
      "        -4.1182e-01, -4.0508e-01, -3.9851e-01, -3.9211e-01, -3.8588e-01,\n",
      "        -3.7979e-01, -3.7386e-01, -3.6807e-01, -3.6242e-01, -3.5690e-01,\n",
      "        -3.5152e-01, -3.4626e-01, -3.4111e-01, -3.3609e-01, -3.3117e-01,\n",
      "        -3.2637e-01, -3.2167e-01, -3.1707e-01, -3.1257e-01, -3.0816e-01,\n",
      "        -3.0385e-01, -2.9963e-01, -2.9549e-01, -2.9144e-01, -2.8747e-01,\n",
      "        -2.8358e-01, -2.7977e-01, -2.7602e-01, -2.7236e-01, -2.6876e-01,\n",
      "        -2.6523e-01, -2.6177e-01, -2.5837e-01, -2.5503e-01, -2.5176e-01,\n",
      "        -2.4854e-01, -2.4538e-01, -2.4228e-01, -2.3924e-01, -2.3624e-01,\n",
      "        -2.3330e-01, -2.3042e-01, -2.2758e-01, -2.2478e-01, -2.2204e-01,\n",
      "        -2.1934e-01, -2.1668e-01, -2.1407e-01, -2.1150e-01, -2.0897e-01,\n",
      "        -2.0648e-01, -2.0403e-01, -2.0162e-01, -1.9925e-01, -1.9691e-01,\n",
      "        -1.9461e-01, -1.9235e-01, -1.9012e-01, -1.8792e-01, -1.8575e-01,\n",
      "        -1.8362e-01, -1.8152e-01, -1.7945e-01, -1.7741e-01, -1.7540e-01,\n",
      "        -1.7342e-01, -1.7146e-01, -1.6953e-01, -1.6763e-01, -1.6576e-01,\n",
      "        -1.6391e-01, -1.6209e-01, -1.6029e-01, -1.5852e-01, -1.5677e-01,\n",
      "        -1.5504e-01, -1.5334e-01, -1.5166e-01, -1.5000e-01, -1.4836e-01,\n",
      "        -1.4674e-01, -1.4515e-01, -1.4357e-01, -1.4202e-01, -1.4048e-01,\n",
      "        -1.3896e-01, -1.3746e-01, -1.3598e-01, -1.3452e-01, -1.3308e-01,\n",
      "        -1.3165e-01, -1.3025e-01, -1.2886e-01, -1.2748e-01, -1.2612e-01,\n",
      "        -1.2478e-01, -1.2346e-01, -1.2215e-01, -1.2085e-01, -1.1957e-01,\n",
      "        -1.1831e-01, -1.1705e-01, -1.1582e-01, -1.1459e-01, -1.1339e-01,\n",
      "        -1.1219e-01, -1.1101e-01, -1.0984e-01, -1.0868e-01, -1.0754e-01,\n",
      "        -1.0640e-01, -1.0528e-01, -1.0418e-01, -1.0308e-01, -1.0200e-01,\n",
      "        -1.0092e-01, -9.9862e-02, -9.8812e-02, -9.7773e-02, -9.6744e-02,\n",
      "        -9.5727e-02, -9.4719e-02, -9.3722e-02, -9.2735e-02, -9.1758e-02,\n",
      "        -9.0792e-02, -8.9835e-02, -8.8887e-02, -8.7949e-02, -8.7020e-02,\n",
      "        -8.6100e-02, -8.5190e-02, -8.4287e-02, -8.3394e-02, -8.2509e-02,\n",
      "        -8.1633e-02, -8.0765e-02, -7.9905e-02, -7.9053e-02, -7.8210e-02,\n",
      "        -7.7374e-02, -7.6546e-02, -7.5726e-02, -7.4913e-02, -7.4108e-02,\n",
      "        -7.3310e-02, -7.2519e-02, -7.1735e-02, -7.0959e-02, -7.0189e-02,\n",
      "        -6.9427e-02, -6.8671e-02, -6.7921e-02, -6.7179e-02, -6.6442e-02,\n",
      "        -6.5713e-02, -6.4989e-02, -6.4272e-02, -6.3561e-02, -6.2856e-02,\n",
      "        -6.2157e-02, -6.1465e-02, -6.0778e-02, -6.0097e-02, -5.9421e-02,\n",
      "        -5.8752e-02, -5.8087e-02, -5.7429e-02, -5.6775e-02, -5.6128e-02,\n",
      "        -5.5485e-02, -5.4848e-02, -5.4215e-02, -5.3589e-02, -5.2967e-02,\n",
      "        -5.2350e-02, -5.1738e-02, -5.1131e-02, -5.0529e-02, -4.9932e-02,\n",
      "        -4.9339e-02, -4.8751e-02, -4.8167e-02, -4.7588e-02, -4.7014e-02,\n",
      "        -4.6444e-02, -4.5878e-02, -4.5317e-02, -4.4760e-02, -4.4207e-02,\n",
      "        -4.3658e-02, -4.3114e-02, -4.2573e-02, -4.2037e-02, -4.1504e-02,\n",
      "        -4.0976e-02, -4.0451e-02, -3.9931e-02, -3.9414e-02, -3.8901e-02,\n",
      "        -3.8392e-02, -3.7886e-02, -3.7384e-02, -3.6886e-02, -3.6391e-02,\n",
      "        -3.5900e-02, -3.5412e-02, -3.4928e-02, -3.4447e-02, -3.3970e-02,\n",
      "        -3.3496e-02, -3.3026e-02, -3.2558e-02, -3.2095e-02, -3.1634e-02,\n",
      "        -3.1176e-02, -3.0722e-02, -3.0270e-02, -2.9822e-02, -2.9377e-02,\n",
      "        -2.8935e-02, -2.8496e-02, -2.8060e-02, -2.7627e-02, -2.7197e-02,\n",
      "        -2.6769e-02, -2.6345e-02, -2.5923e-02, -2.5504e-02, -2.5088e-02,\n",
      "        -2.4674e-02, -2.4264e-02, -2.3856e-02, -2.3450e-02, -2.3048e-02,\n",
      "        -2.2647e-02, -2.2250e-02, -2.1855e-02, -2.1462e-02, -2.1072e-02,\n",
      "        -2.0685e-02, -2.0300e-02, -1.9917e-02, -1.9537e-02, -1.9159e-02,\n",
      "        -1.8784e-02, -1.8410e-02, -1.8040e-02, -1.7671e-02, -1.7305e-02,\n",
      "        -1.6941e-02, -1.6579e-02, -1.6219e-02, -1.5862e-02, -1.5507e-02,\n",
      "        -1.5154e-02, -1.4803e-02, -1.4454e-02, -1.4107e-02, -1.3763e-02,\n",
      "        -1.3420e-02, -1.3080e-02, -1.2741e-02, -1.2405e-02, -1.2070e-02,\n",
      "        -1.1737e-02, -1.1407e-02, -1.1078e-02, -1.0751e-02, -1.0427e-02,\n",
      "        -1.0104e-02, -9.7825e-03, -9.4633e-03, -9.1459e-03, -8.8303e-03,\n",
      "        -8.5165e-03, -8.2045e-03, -7.8942e-03, -7.5857e-03, -7.2790e-03,\n",
      "        -6.9740e-03, -6.6707e-03, -6.3691e-03, -6.0692e-03, -5.7709e-03,\n",
      "        -5.4743e-03, -5.1794e-03, -4.8861e-03, -4.5944e-03, -4.3043e-03,\n",
      "        -4.0158e-03, -3.7289e-03, -3.4435e-03, -3.1597e-03, -2.8774e-03,\n",
      "        -2.5967e-03, -2.3174e-03, -2.0397e-03, -1.7634e-03, -1.4886e-03,\n",
      "        -1.2153e-03, -9.4347e-04, -6.7305e-04, -4.0406e-04, -1.3648e-04,\n",
      "         1.2969e-04,  3.9446e-04,  6.5784e-04,  9.1985e-04,  1.1805e-03,\n",
      "         1.4398e-03,  1.6977e-03,  1.9544e-03,  2.2097e-03,  2.4637e-03,\n",
      "         2.7164e-03,  2.9678e-03,  3.2179e-03,  3.4668e-03,  3.7143e-03],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 10\n",
    "for epoch in range(1, 11):\n",
    "    # backprop on rows\n",
    "    cs.qs.requires_grad = True\n",
    "    cs.ps.requires_grad = False\n",
    "    r2 = cs()\n",
    "    print(r2)\n",
    "    loss = r2\n",
    "    loss.backward() \n",
    "    with torch.no_grad():\n",
    "        cs.qs -= learning_rate * cs.qs.grad\n",
    "    proj = project_onto_simplex(cs.qs.cpu().numpy(), l, n)\n",
    "    cs.qs.data = torch.Tensor(proj).to(\"cuda\")\n",
    "    # backprop on cols\n",
    "    cs.qs.requires_grad = False\n",
    "    cs.ps.requires_grad = True\n",
    "    r2 = cs()\n",
    "    print(r2)\n",
    "    loss = -r2\n",
    "    loss.backward() \n",
    "    with torch.no_grad():\n",
    "        cs.ps -= learning_rate * cs.ps.grad\n",
    "    proj = project_onto_simplex(cs.ps.cpu().numpy(), k, m)\n",
    "    cs.ps.data = torch.Tensor(proj).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c060cd-bf48-4244-bcd7-1aee8b97e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 11):\n",
    "    t_k = 2/(epoch+2)\n",
    "    # backprop on rows\n",
    "    cs.qs.requires_grad = True\n",
    "    cs.ps.requires_grad = False\n",
    "    r2 = cs()\n",
    "    print(r2)\n",
    "    loss = r2\n",
    "    loss.backward() \n",
    "    with torch.no_grad():\n",
    "        y = frank_wolfe(cs.qs.grad, l, n)\n",
    "    cs.qs.data = (1-t_k) * cs.qs.data + t_k * torch.Tensor(y).to(\"cuda\")\n",
    "    # backprop on cols\n",
    "    cs.qs.requires_grad = False\n",
    "    cs.ps.requires_grad = True\n",
    "    r2 = cs()\n",
    "    print(r2)\n",
    "    loss = -r2\n",
    "    loss.backward() \n",
    "    with torch.no_grad():\n",
    "        y = frank_wolfe(cs.ps.grad, k, m)\n",
    "    t_k = 2/(epoch+2)\n",
    "    cs.ps.data = (1-t_k) * cs.ps.data + t_k * torch.Tensor(y).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30e0000e-afd0-470a-a63d-4e3871cb9471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([252, 269, 276, 311, 349, 350, 351, 353, 354, 355, 356, 357, 358,\n",
       "        359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373,\n",
       "        374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
       "        387, 388, 389, 390, 391, 392, 393, 394]),)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(cs.qs.data.cpu().numpy() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b47273a2-ee12-4b14-9dee-e16ff01d3e65",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['G3'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mG3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns[(cs\u001b[38;5;241m.\u001b[39mps\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/core/frame.py:5391\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5243\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5245\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5252\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5254\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5255\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5256\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5389\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5397\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5398\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/core/generic.py:4510\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4508\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4510\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4513\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/core/generic.py:4551\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4549\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4551\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4552\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4554\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/opence-v1.7.2/lib/python3.9/site-packages/pandas/core/indexes/base.py:6972\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6972\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6973\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['G3'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def validate(ps, qs):\n",
    "    \n",
    "    cols = features.columns[(ps == 1).cpu().numpy()]\n",
    "    features[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5078d1-398f-48ad-af24-410eda27b2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wmlce-v1.7.0]",
   "language": "python",
   "name": "conda-env-wmlce-v1.7.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
